# -*- coding: utf-8 -*-
"""HousePricePrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XOTJEl5gU0zjoJh7-Os0QgxqLkbi5InK

**House Price Prediction**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')

data = pd.read_csv('/content/Hyderbad_House_price.csv')

data.head()

data.tail()

data.describe()

data.columns

data.info()

sns.pairplot(data)

import plotly.express as px
import plotly.graph_objects
figure = px.scatter(data_frame = data, x="location",
                    y="price(L)", size="price(L)")
figure.show()

correlation = data.select_dtypes(include=np.number).corr()
print(correlation)

plt.figure(figsize=(10,10))
sns.heatmap(correlation, cbar=True, square=True, fmt='.1f',
            annot=True, annot_kws={'size':8}, cmap='Blues')

feature_cols = ['title','location','price(L)','rate_persqft','area_insqft','building_status']
x=data[feature_cols]
y=data['price(L)']

data

data.dropna(inplace=True)

data

data.location.value_counts()

data ['location'] = data['location'].apply(lambda x: x.strip())

data.location.value_counts()

location_stats = data.groupby('location')['location'].agg('count')

location_less_than_10_entries = location_stats[location_stats <= 10 ]

data

location_less_than_10_entries

data['location'] = data['location'].apply(lambda x:'other' if x in location_less_than_10_entries else x)

data['location'].value_counts()

data['area_insqft'] = data['area_insqft'].apply(lambda x:x.replace('\t','')if isinstance(x,str)else x)

data['area_insqft'].unique()

data.area_insqft.unique()

def clean(sqft):
  if isinstance(sqft, str):
    sqft = sqft.lower().replace('sqft', '').strip()
    if 'sqyrd' in sqft:
      try:
        return float(sqft.replace('sqyrd', '').strip()) * 9
      except:
        return None
    tokens = sqft.split('-')
    if len(tokens) == 2:
      try:
        return (float(tokens[0])+float(tokens[1]))/2
      except:
        return None
    try:
      return float(sqft)
    except:
      return None
  return None

data.describe()

from sklearn.preprocessing import OneHotEncoder,StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
from sklearn.compose import make_column_transformer

col_trans = make_column_transformer((OneHotEncoder(sparse_output = False),['location']),
                                    remainder='passthrough')
lr = LinearRegression()
scaler = StandardScaler() # Create an instance of StandardScaler
model = make_pipeline(col_trans,scaler,lr)

x = data[['title','location','price(L)','rate_persqft','area_insqft','building_status']]
y = data['price(L)']

df = pd.DataFrame(x)

labelEncoder = {}
categorical_columns = ['title','price(L)','location','rate_persqft','area_insqft','building_status']

df,test_df = train_test_split(df, test_size=0.2 , random_state=42)
display(df.shape)

df.isna().sum()

print("Number of duplicate rows:",df.duplicated(subset=None, keep='first').sum())

df.drop_duplicates(subset=None, keep='first',inplace=True)

amenities_cols = df.drop(columns=['title','price(L)','location','rate_persqft','area_insqft','building_status']).columns
plt.figure(figsize=(15,15))
for n, variables in enumerate(amenities_cols):
  plt.subplot(7,6,n+1)
  g=sns.countplot(data=df,x=df[variables],ax=ax)
  plt.tight_layout()

data2 = data

data2

from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import make_column_transformer, ColumnTransformer
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

col_trans = make_column_transformer((OneHotEncoder(sparse_output=False),['location']),
                                    remainder='passthrough')
lr = LinearRegression()
scaler = StandardScaler()
model = make_pipeline(col_trans,scaler,lr)

data_input = data2.drop(columns=['price(L)'])
data_output = data['price(L)']

x_train,x_test,y_train,y_test = train_test_split(data_input.drop(columns=['Unnamed: 0']),data_output,test_size=0.2,random_state=42)

"""Now that the model has been trained, let's evaluate its performance and make some predictions."""

display(x_train,y_train,x_test,y_test)

plt.scatter(y_train,model.predict(x_train))
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.title('Actual Prices vs Predicted Prices')
plt.show()

# Impute missing values in 'area_insqft' with the mean
mean_area = data['area_insqft'].mean()
data['area_insqft'].fillna(mean_area, inplace=True)
display(data.isna().sum())

# Use the pipeline to fit the model
model.fit(x_train,y_train)
y_pred=model.predict(x_test)

df = pd.DataFrame(data[['title','area_insqft','rate_persqft','location','price(L)', 'building_status']])

X = df[['title','area_insqft','rate_persqft','location', 'building_status']]
y = df['price(L)']

categorical_features = ['title','location', 'building_status']
numerical_features = ['area_insqft','rate_persqft']

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
        ('num', StandardScaler(), numerical_features)
    ],
    remainder='drop'
)

model = Pipeline(steps=[('preprocessor', preprocessor),
                        ('regressor', LinearRegression())])

model.fit(X,y)

display(x_train.info())
display(x_train.head())

model.fit(x_train, y_train)

plt.scatter(y_train, model.predict(x_train))
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.title('Actual Prices vs Predicted Prices (Training Data)')
plt.show()

plt.scatter(y_test, model.predict(x_test))
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.title('Actual Prices vs Predicted Prices (Test Data)')
plt.show()

model.score(x_test,y_test)

input = pd.DataFrame([['Residential Plot','Taramatipet','2222','1800','	New']], columns=['title', 'location', 'rate_persqft', 'area_insqft', 'building_status'])

from sklearn.metrics import mean_squared_error, r2_score

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"R-squared: {r2:.2f}")

model.predict(input)

import pickle
with open("Model.pkl", "wb") as file:
    pickle.dump(model, file)
    print("Model saved to 'Model.pkl")

data2.to_csv('cleaned_data.csv')

data['price_per_sqft'] = data['price(L)'] * 100000 / data['area_insqft']
data['building_status_encoded'] = data['building_status'].apply(lambda x: 0 if x == 'Ready to move' else 1)
display(data.head())